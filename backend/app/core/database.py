"""ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šè¨­å®š / SQLAlchemyã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†."""

import logging
import os
import subprocess
from collections.abc import Generator
from pathlib import Path

from sqlalchemy import create_engine, event, text
from sqlalchemy.orm import Session, sessionmaker

# ãƒ¢ãƒ‡ãƒ«ç™»éŒ²ï¼ˆinit_dbå†…ã§importã™ã‚‹ãŒã€å‹å‚ç…§ã®ãŸã‚ã“ã“ã«ã‚‚ç½®ã„ã¦å•é¡Œãªã—ï¼‰
from app.models.base_model import set_sqlite_pragma

from .config import settings


logger = logging.getLogger(__name__)

# --- Engine ---------------------------------------------------------------
engine = create_engine(
    settings.DATABASE_URL,
    connect_args={"check_same_thread": False} if "sqlite" in settings.DATABASE_URL else {},
    echo=settings.ENVIRONMENT == "development",  # é–‹ç™ºæ™‚ã¯SQLãƒ­ã‚°
)
if engine.dialect.name == "sqlite":
    event.listen(engine, "connect", set_sqlite_pragma)

# --- Session --------------------------------------------------------------
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)


def get_db() -> Generator[Session, None, None]:
    """FastAPI ä¾å­˜æ€§æ³¨å…¥ç”¨ã®DBã‚»ãƒƒã‚·ãƒ§ãƒ³."""
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


# --- Schema lifecycle -----------------------------------------------------
def init_db() -> None:
    """
    DBåˆæœŸåŒ–ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆã¯Alembicã«å§”è­²ï¼‰
    Alembicãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã™.
    """
    import app.models  # noqa: F401  ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ãŸã‚ã®å‰¯ä½œç”¨import

    # Alembicãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ
    try:
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆalembic.iniãŒã‚ã‚‹å ´æ‰€ï¼‰
        backend_dir = Path(__file__).parent.parent.parent

        logger.info("ğŸ”„ Running Alembic migrations to create tables...")
        result = subprocess.run(
            ["alembic", "upgrade", "head"],
            cwd=backend_dir,
            capture_output=True,
            text=True,
            check=True,
        )
        logger.info("âœ… Alembic migrations completed successfully")
        if result.stdout:
            logger.debug(f"Alembic output: {result.stdout}")
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ Alembic migration failed: {e}")
        logger.error(f"stdout: {e.stdout}")
        logger.error(f"stderr: {e.stderr}")
        raise RuntimeError(f"Failed to run Alembic migrations: {e.stderr}")
    except Exception as e:
        logger.error(f"âŒ Unexpected error running Alembic: {e}")
        raise


def _drop_dependent_views() -> None:
    """
    ãƒ†ãƒ¼ãƒ–ãƒ«ä¾å­˜ã®VIEWã‚’å…ˆã«DROPã™ã‚‹ã€‚
    ä¾å­˜ã§è½ã¡ã‚‹ä»£è¡¨VIEWã‚’ã“ã“ã¸åˆ—æŒ™ã€‚å­˜åœ¨ã—ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã€‚.
    """
    if "sqlite" in settings.DATABASE_URL:
        return

    dependent_views = [
        # åœ¨åº«é›†è¨ˆãƒ“ãƒ¥ãƒ¼ï¼ˆStockMovementã«ä¾å­˜ï¼‰
        "lot_current_stock",
        # è¿½åŠ ã®VIEWãŒã‚ã‚Œã°ã“ã“ã«è¿½è¨˜
        # "lot_daily_stock",
    ]

    with engine.begin() as conn:
        for view_name in dependent_views:
            try:
                conn.execute(text(f"DROP VIEW IF EXISTS {view_name} CASCADE"))
                logger.info(f"ğŸ—‘ï¸ Dropped view: {view_name}")
            except Exception as e:
                logger.warning(f"âš ï¸ VIEWå‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸ ({view_name}): {e}")


def truncate_all_tables() -> None:
    """
    å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ï¼ˆé–‹ç™º/æ¤œè¨¼ç”¨é€”ï¼‰
    - ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã¯ä¿æŒ
    - alembic_versionã¯é™¤å¤–ã—ã¦ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ã‚’ä¿æŒ
    - TRUNCATE ... RESTART IDENTITY CASCADEã§å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’ç„¡è¦–.
    """
    if settings.ENVIRONMENT == "production":
        raise ValueError("æœ¬ç•ªç’°å¢ƒã§ã¯ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤ã¯ã§ãã¾ã›ã‚“")

    # SQLite: å¾“æ¥ã®drop_db()ã‚’ä½¿ç”¨
    if "sqlite" in settings.DATABASE_URL:
        logger.warning("âš ï¸ SQLiteç’°å¢ƒã§ã¯TRUNCATEãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€drop_db()ã‚’ä½¿ç”¨ã—ã¾ã™")
        drop_db()
        return

    # PostgreSQL: å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’TRUNCATE
    logger.info("ğŸ—‘ï¸ Truncating all tables in schema 'public'...")
    with engine.begin() as conn:
        # publicé…ä¸‹ã®å…¨ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’å–å¾—ï¼ˆalembic_versionã‚’é™¤ãï¼‰
        result = conn.execute(
            text("""
            SELECT tablename
            FROM pg_tables
            WHERE schemaname = 'public'
            AND tablename != 'alembic_version'
            ORDER BY tablename
        """)
        )
        tables = [row[0] for row in result]

        if not tables:
            logger.info("â„¹ï¸ Truncateå¯¾è±¡ã®ãƒ†ãƒ¼ãƒ–ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        # TRUNCATEå®Ÿè¡Œï¼ˆRESTART IDENTITYã§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚‚ãƒªã‚»ãƒƒãƒˆã€CASCADEã§å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’ç„¡è¦–ï¼‰
        for table in tables:
            conn.execute(text(f'TRUNCATE TABLE "{table}" RESTART IDENTITY CASCADE'))
            logger.debug(f"  - Truncated: {table}")

        logger.info(f"âœ… {len(tables)} ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

    logger.info("â„¹ï¸ alembic_versionã¯ä¿æŒã•ã‚Œã¾ã—ãŸï¼ˆãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ã‚’ç¶­æŒï¼‰")


def drop_db() -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰Šé™¤ï¼ˆé–‹ç™º/æ¤œè¨¼ç”¨é€”ï¼‰
    - SQLite: ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
    - PostgreSQL: ã‚¹ã‚­ãƒ¼ãƒ public ã‚’ CASCADE ã§è½ã¨ã—ã¦å†ä½œæˆ.

    âš ï¸ æ¨å¥¨: ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹å ´åˆã¯ truncate_all_tables() ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„
    """
    if settings.ENVIRONMENT == "production":
        raise ValueError("æœ¬ç•ªç’°å¢ƒã§ã¯ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å‰Šé™¤ã¯ã§ãã¾ã›ã‚“")

    # SQLite: ç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆå¾“æ¥ã©ãŠã‚Šï¼‰
    if "sqlite" in settings.DATABASE_URL:
        engine.dispose()
        try:
            db_path_str = settings.DATABASE_URL.split(":///")[1]
        except IndexError:
            return
        db_path = Path(db_path_str)
        if db_path.exists():
            os.remove(db_path)
            logger.info("ğŸ—‘ï¸ Deleted SQLite database file")
        return

    # PostgreSQL: ã‚¹ã‚­ãƒ¼ãƒã”ã¨åˆæœŸåŒ–
    logger.info("ğŸ—‘ï¸ Dropping and recreating schema 'public'...")
    with engine.begin() as conn:
        # å¿…è¦ãªã‚‰åˆ¥ã‚¹ã‚­ãƒ¼ãƒåã«å¤‰æ›´ï¼ˆé€šå¸¸ã¯ publicï¼‰
        schema = "public"
        conn.execute(text(f'DROP SCHEMA IF EXISTS "{schema}" CASCADE;'))
        conn.execute(text(f'CREATE SCHEMA "{schema}";'))
        # æ¤œç´¢ãƒ‘ã‚¹ã‚’æˆ»ã™ï¼ˆä»»æ„ï¼‰
        conn.execute(text(f'SET search_path TO "{schema}";'))
        logger.info(f"âœ… Schema '{schema}' has been recreated")

    # æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ç ´æ£„
    engine.dispose()
    logger.info("â„¹ï¸ DBã‚¨ãƒ³ã‚¸ãƒ³ã‚’ç ´æ£„ã—ã¾ã—ãŸ (æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚º)")
